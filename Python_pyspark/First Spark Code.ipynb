{"cells":[{"cell_type":"code","source":["from pyspark import SparkConf, SparkContext\n# SparkCof- will allow us to put some configurations for our spark, like reading data from some external DB we need some configurations we can put them here\n# SparkContext- it is actually the entry point of the spark inside the cluster"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c62ec2f9-10fe-44c2-afd9-6650a63f2089"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["conf = SparkConf().setAppName(\"Read File\") # it will provide the basic configuration\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3028450d-5d7f-4a3f-b1d6-94c0738d8781"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# here is where the spark magic starts\nsc=SparkContext.getOrCreate(conf=conf) # it will check the if SparkContext is already available it will return or if not it will create one, it will crate or get sparkcontext for us\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24264e43-403a-43cb-bc31-0a1532899f54"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# reading the file\ntext =sc.textFile('/FileStore/tables/sample.txt') # it is mainly transformation, spark wan't start reading data immediately because transformation is lazy evaluation."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"35d3ded6-3435-4ea6-b0a7-bd5166122340"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["text.collect() # it is called action, from here only code will read the data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7126fe7a-3831-45b9-a994-945f5c1f78e8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[14]: ['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[14]: ['1 2 3 4 5', '3 4 5 66 77', '12 43 6 7 8', '12 12 33']"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f2642b4b-9dd9-42eb-a4e6-cf656056e3ca"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"First Spark Code","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":1759065823660339}},"nbformat":4,"nbformat_minor":0}
